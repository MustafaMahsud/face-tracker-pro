<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>FaceTracker Pro</title>
  <script src="https://cdn.tailwindcss.com"></script>

  <style>
    body {
      @apply bg-slate-900 text-white flex flex-col items-center justify-center min-h-screen;
    }
    #tracker-container {
      position: relative;
      width: 90vw;
      max-width: 480px;
      aspect-ratio: 3/4;
      overflow: hidden;
      border-radius: 1rem;
      border: 2px solid rgba(255,255,255,0.1);
      box-shadow: 0 0 20px rgba(0,0,0,0.4);
    }
    video, canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
      border-radius: 1rem;
    }
  </style>
</head>
<body class="p-4 space-y-6">

  <h1 class="text-3xl font-bold text-cyan-400">FaceTracker Pro</h1>
  <p class="text-slate-400">Realtime face circle — smooth, on-device tracking</p>

  <div id="tracker-container">
    <video id="video" autoplay playsinline muted></video>
    <canvas id="overlay"></canvas>
  </div>

  <div class="flex gap-3">
    <button id="startBtn" class="bg-green-600 hover:bg-green-700 px-4 py-2 rounded-xl">Start Camera</button>
    <button id="stopBtn" class="bg-red-600 hover:bg-red-700 px-4 py-2 rounded-xl">Stop</button>
  </div>

  <p class="text-slate-500 text-sm">Works fully on-device. Use Safari (iOS) or Chrome (Android). Requires HTTPS.</p>

  <script type="module">
    import {
      FaceDetector,
      FilesetResolver
    } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";

    const video = document.getElementById("video");
    const canvas = document.getElementById("overlay");
    const ctx = canvas.getContext("2d");
    let detector, stream, running = false;

    async function initDetector() {
      console.log("Loading FaceDetector...");
      const vision = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
      );
      detector = await FaceDetector.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath:
            "https://storage.googleapis.com/mediapipe-models/face_detector/face_detector/float16/1/face_detector.task",
        },
        runningMode: "VIDEO",
      });
      console.log("✅ FaceDetector loaded");
    }

    async function startCamera() {
      try {
        console.log("Requesting camera...");
        stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        video.style.display = "block";
        console.log("✅ Camera ready");
        await new Promise(resolve => video.onloadedmetadata = resolve);
        resizeCanvas();
        running = true;
        detectLoop();
      } catch (err) {
        console.error("Camera error:", err);
        alert("Camera access denied or not available");
      }
    }

    function stopCamera() {
      running = false;
      if (stream) stream.getTracks().forEach(t => t.stop());
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      console.log("Camera stopped");
    }

    function resizeCanvas() {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      console.log("Canvas resized:", canvas.width, "x", canvas.height);
    }

    async function detectLoop() {
      if (!running || !detector) return;
      const result = await detector.detectForVideo(video, Date.now());
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      if (result.detections.length > 0) {
        const box = result.detections[0].boundingBox;
        const cx = box.originX + box.width / 2;
        const cy = box.originY + box.height / 2;
        const r = Math.max(box.width, box.height) / 2.2;
        ctx.beginPath();
        ctx.strokeStyle = "#22d3ee";
        ctx.lineWidth = 4;
        ctx.arc(cx, cy, r, 0, 2 * Math.PI);
        ctx.stroke();
      }

      requestAnimationFrame(detectLoop);
    }

    document.getElementById("startBtn").onclick = async () => {
      if (!detector) await initDetector();
      await startCamera();
    };

    document.getElementById("stopBtn").onclick = stopCamera;
  </script>
</body>
</html>
